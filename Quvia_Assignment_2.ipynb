{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObabmersszYrl/6GZXzzaK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrigoa/random/blob/main/Quvia_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "yLBqqWVEDEuf",
        "outputId": "4db5446a-e271-4f1c-d53c-555e09ba4824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gurobipy\n",
            "  Downloading gurobipy-12.0.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (16 kB)\n",
            "Downloading gurobipy-12.0.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (14.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gurobipy\n",
            "Successfully installed gurobipy-12.0.1\n",
            "Restricted license - for non-production use only - expires 2026-11-23\n",
            "Warning: linear constraint 0 and linear constraint 1 have the same name \"QoE_Hour_Consumption\"\n",
            "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
            "\n",
            "CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz, instruction set [SSE2|AVX|AVX2]\n",
            "Thread count: 1 physical cores, 2 logical processors, using up to 2 threads\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "GurobiError",
          "evalue": "Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0ea64452a74b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0mmip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqoe_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAXIMIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0mmip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mip.lp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m \u001b[0mmip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/gurobipy/_model.pyx\u001b[0m in \u001b[0;36mgurobipy._model.Model.optimize\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mGurobiError\u001b[0m: Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information"
          ]
        }
      ],
      "source": [
        "\"\"\"Random.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/shrigoa/random/blob/main/Random.ipynb\n",
        "\n",
        "Problem:\n",
        "1. Manage internet bandwidth usage on a ship.\n",
        "\n",
        "Important data:\n",
        "1. Access to two communication links each contracted with 15TB of bandwidth for a month, thus, total of 30TB.\n",
        "\n",
        "Goals:\n",
        "1. Optimal usage: Bandwidth should be consumed only when required and minimized when not needed.\n",
        "2.a. Fairness Across Time: Quality of Experience (QoE) should be consistent across different timeslots.\n",
        "2.b. Significant variations — such as excellent QoE in some periods and poor QoE in others — must be inimized to avoid service quality alarms.\n",
        "2.c. Demand met percentage is the QoE. It should not vary much.\n",
        "\n",
        "Given Data:\n",
        "1. Per hour demand data for upstream and downstream traffic\n",
        "- Variations of 20-25% are possible\n",
        "- Columns: Time slots, downstream demand, upstream demand\n",
        "2. Ship arrival at ports\n",
        "- Variation of 1-2 hours earlier or later.\n",
        "- Demand drops 50% at port compared to sea.\n",
        "- Columns: Port, Arrival Time, Departure Time\n",
        "3. Link Downtime\n",
        "- One of the links will be unavailable on certain days.\n",
        "- This downtime must be configurable in the code.\n",
        "- During downtime, the algorithm must reserve enough bandwidth on the remaining active link to maintain stable QoE and avoid service degradation.\n",
        "4. Consumption Limits:\n",
        "- Each link supports maximum bandwidth of 500Mbps at any given point.\n",
        "- Bandwidth planning is done in 5 min time-slots.\n",
        "- Bandwidth volume (e.g., 1 GB in 5 minutes) will internally be converted into rate for enforcement.\n",
        "5. End of the month requirement:\n",
        "- Allocated 30TB should be completely used. (CONSTRAINT)\n",
        "- No under/over usage allowed.\n",
        "6. Objective:\n",
        "- Demand met percentage is the QoE (OBJECTIVE FUNCTION).\n",
        "- Needs to be as high as possible.\n",
        "\n",
        "7. Parameters:\n",
        "- Number of 5 mins slots per day: 288 slots\n",
        "- Number of slots per hour: 12 slots\n",
        "- Number of days: 30 days\n",
        "- Seconds in each slot:\n",
        "- Downtime start day: 19\n",
        "- Downtime end day: 27\n",
        "- Capacity per link: 15 TB\n",
        "- Number of links: 2\n",
        "- Number of links up during downtime: 1\n",
        "- Maximum bandwidth of any link: 500 Mbps\n",
        "\n",
        "7. Decision Variables\n",
        "- How much data is consumed in each 5 mins slot: data_consumed[day, hour, slot]\n",
        "\n",
        "8. Objective Function\n",
        "- demand[day, hour] - sum of data_consumed[day, hour, slot] over all slots for each day, for each hour data\n",
        "\"\"\"\n",
        "#Install packages\n",
        "!pip install gurobipy\n",
        "\n",
        "#Import packages\n",
        "import random\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Parameters\n",
        "#Fixed Parameters\n",
        "hours_in_day = 24\n",
        "mins_in_hour = 60\n",
        "secs_in_min = 60\n",
        "\n",
        "#Configurable Parameters\n",
        "slot_mins = 5\n",
        "planning_start_date = datetime(2025, 5, 1)\n",
        "num_planning_days = 30\n",
        "active_links = 2\n",
        "cap_per_link = 15000\n",
        "max_bandwidth_per_link = 0.5\n",
        "downtime_start_day = datetime(2025, 5, 20)\n",
        "downtime_end_day = datetime(2025, 5, 28)\n",
        "active_links_downtime = 1\n",
        "allowed_QoE_variance_percent = 0.01\n",
        "days_to_consider = 3\n",
        "\n",
        "#Derived Parameters\n",
        "secs_in_hour = mins_in_hour * secs_in_min\n",
        "planning_end_date = planning_start_date + timedelta(days = num_planning_days - 1)\n",
        "seconds_in_slot = slot_mins * secs_in_min\n",
        "seconds_in_hour = mins_in_hour * secs_in_min\n",
        "slots_per_hour = int(mins_in_hour/slot_mins)\n",
        "slots_per_day = int(slots_per_hour * hours_in_day)\n",
        "\n",
        "total_cap = cap_per_link * active_links\n",
        "total_cap_downtime = cap_per_link * active_links_downtime\n",
        "\n",
        "max_data_per_slot_per_link = max_bandwidth_per_link * seconds_in_slot\n",
        "max_data_per_hour_per_link = max_data_per_slot_per_link * slots_per_hour\n",
        "\n",
        "max_data_per_slot = max_data_per_slot_per_link * active_links\n",
        "max_data_per_hour = max_data_per_hour_per_link * active_links\n",
        "\n",
        "downtime_max_data_per_slot = max_data_per_slot_per_link * active_links_downtime\n",
        "downtime_max_data_per_hour = max_data_per_hour_per_link * active_links_downtime\n",
        "\n",
        "downtime_start_day_num = (downtime_start_day - planning_start_date).days\n",
        "downtime_end_day_num = (downtime_end_day - planning_start_date).days\n",
        "\n",
        "max_bandwidth = max_bandwidth_per_link * active_links\n",
        "downtime_max_bandwidth = max_bandwidth_per_link * active_links_downtime\n",
        "\n",
        "allowed_QoE_variance = allowed_QoE_variance_percent/100\n",
        "#---------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Data Creation\n",
        "try:\n",
        "  input_data_df = pd.read_csv(\"Input Demand.csv\")\n",
        "except:\n",
        "  input_data_df = pd.DataFrame(columns = ['Day', 'Date', 'Hour', 'Downstream Demand', 'Upstream Demand', 'Total Demand', 'Variation %', 'Final Demand', 'Demand Met', 'QoE %', 'Proposed Consumption Per Slot', 'Proposed Slot Speed'])\n",
        "  for day in range(num_planning_days):\n",
        "    date = planning_start_date + timedelta(days=day)\n",
        "    for hour in range(hours_in_day):\n",
        "      downstream_demand = random.randint(10, 40)\n",
        "      upward_demand = random.randint(10, 40)\n",
        "      total_demand = downstream_demand + upward_demand\n",
        "      variation_percentage = 20 if 9 <= hour < 21 else 10\n",
        "      final_demand = round((1 + variation_percentage/100) * total_demand)\n",
        "      input_data_df.loc[len(input_data_df)] = [day, date, hour, downstream_demand, upward_demand, total_demand, variation_percentage, final_demand, \"\", \"\", \"\", \"\"]\n",
        "  input_data_df.to_csv(\"Input Demand.csv\", index=False)\n",
        "\n",
        "#Replacing 0 demand with 1 GB Demand\n",
        "input_data_df['Final Demand'] = input_data_df['Final Demand'].mask(input_data_df['Final Demand']==0).fillna(1)\n",
        "\n",
        "#Total percentage of demand that would be fulfilled\n",
        "final_demand =  input_data_df.loc[:,'Final Demand'].sum()\n",
        "total_fulfilled_percentage = total_cap / final_demand if total_cap / final_demand < 1 else 1\n",
        "#---------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Define Model\n",
        "env = gp.Env()\n",
        "#env.setParam('OutputFlag', 0)\n",
        "mip = gp.Model('PlanningMIP', env = env)\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Decision Variables\n",
        "hour_consumption = {}\n",
        "QoE = {}\n",
        "\n",
        "for day in range(num_planning_days):\n",
        "  for hour in range(hours_in_day):\n",
        "    max_available_data_per_hour = downtime_max_data_per_hour if downtime_start_day_num <= day <= downtime_end_day_num else max_data_per_hour\n",
        "    max_available_data_per_slot = downtime_max_data_per_slot if downtime_start_day_num <= day <= downtime_end_day_num else max_data_per_slot\n",
        "\n",
        "    hour_consumption[day, hour] = mip.addVar(lb = 0, ub = max_available_data_per_hour, vtype=GRB.CONTINUOUS, name = f'hour_consumption_{day}_{hour}')\n",
        "    QoE[day, hour] = mip.addVar(lb = 0, ub = max_available_data_per_hour, vtype=GRB.CONTINUOUS, name = f'qoe_{day}_{hour}')\n",
        "\n",
        "sum_demand_met =  gp.quicksum(hour_consumption[day, hour] for hour in range(hours_in_day) for day in range(num_planning_days))\n",
        "average_demand_met = sum_demand_met/(num_planning_days * hours_in_day)\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Constraints\n",
        "#QoE and Hour Consumption Relation\n",
        "for day in range(num_planning_days):\n",
        "  date = planning_start_date + timedelta(days=day)\n",
        "  for hour in range(hours_in_day):\n",
        "    max_bandwidth = max_bandwidth_per_link\n",
        "    max_available_data_per_slot = downtime_max_data_per_slot if downtime_start_day_num <= day <= downtime_end_day_num else max_data_per_slot\n",
        "\n",
        "    current_hour_demand = input_data_df[(input_data_df['Day'] == day) & (input_data_df['Hour'] == hour)]['Final Demand']\n",
        "    mip.addConstr(QoE[day, hour] <= hour_consumption[day, hour]/current_hour_demand, name=f'QoE_Hour_Consumption')\n",
        "\n",
        "#Slot and Hour Consumption\n",
        "for day in range(num_planning_days):\n",
        "  for hour in range(hours_in_day):\n",
        "    allowed_bandwidth = downtime_max_bandwidth if downtime_start_day_num <= day <= downtime_end_day_num else max_bandwidth\n",
        "    mip.addConstr(hour_consumption[day, hour]/seconds_in_hour <= allowed_bandwidth, name=f'bandwidth_limits')\n",
        "\n",
        "#Total Capacity Constraint\n",
        "data_consumed_exp = gp.LinExpr()\n",
        "for day in range(num_planning_days):\n",
        "  for hour in range(hours_in_day):\n",
        "    data_consumed_exp += hour_consumption[day, hour]\n",
        "mip.addConstr(data_consumed_exp == total_cap, name=f'total_data_consumed')\n",
        "\n",
        "#Maximum Capacity Allowed during Downtime Constraint\n",
        "downtime_data_consumed_exp = gp.LinExpr()\n",
        "for day in range(downtime_start_day_num, downtime_end_day_num + 1):\n",
        "  for hour in range(hours_in_day):\n",
        "    downtime_data_consumed_exp += hour_consumption[day, hour]\n",
        "mip.addConstr(downtime_data_consumed_exp <= total_cap_downtime, name=f'downtime_data_consumed')\n",
        "\n",
        "#Variance Constraint\n",
        "previous_hour_demand = input_data_df[(input_data_df['Day'] == num_planning_days - 1)  & (input_data_df['Hour'] == hours_in_day - 1)]['Final Demand']\n",
        "previous_hour_consumption = hour_consumption[num_planning_days - 1, hours_in_day - 1]\n",
        "\n",
        "previous_hour_qoe = QoE[num_planning_days - 1, hours_in_day - 1]\n",
        "for day in range(num_planning_days):\n",
        "  for hour in range(hours_in_day):\n",
        "    mip.addLConstr(QoE[day, hour], GRB.GREATER_EQUAL, previous_hour_qoe - allowed_QoE_variance, name=f'unmet_demand_constraint')\n",
        "    mip.addLConstr(QoE[day, hour], GRB.LESS_EQUAL, previous_hour_qoe + allowed_QoE_variance, name=f'unmet_demand_constraint')\n",
        "    previous_hour_qoe = QoE[day, hour]\n",
        "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Objective\n",
        "qoe_exp = gp.LinExpr()\n",
        "for day in range(num_planning_days):\n",
        "  for hour in range(hours_in_day):\n",
        "    qoe_exp += QoE[day, hour]\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Solve Model\n",
        "mip.setObjective(qoe_exp, GRB.MAXIMIZE)\n",
        "mip.write('mip.lp')\n",
        "mip.optimize()\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Result\n",
        "if mip.status == GRB.OPTIMAL:\n",
        "  print(\"Found Optimal Solution!!\")\n",
        "  print(\"Objective\", mip.ObjVal)\n",
        "\n",
        "  counter = 0\n",
        "  for day in range(num_planning_days):\n",
        "    for hour in range(hours_in_day):\n",
        "      input_data_df.loc[counter, \"Demand Met\"] = hour_consumption[day, hour].X\n",
        "      input_data_df.loc[counter, \"QoE %\"] = QoE[day, hour].X * 100\n",
        "      input_data_df.loc[counter, \"Proposed Consumption Per Slot\"] = hour_consumption[day, hour].X/slots_per_hour\n",
        "      input_data_df.loc[counter, \"Proposed Slot Speed\"] = (input_data_df.loc[counter, \"Proposed Consumption Per Slot\"] * 1000)/seconds_in_slot\n",
        "      counter += 1\n",
        "elif mip.status == GRB.INFEASIBLE:\n",
        "  print('Infeasible Model')\n",
        "else:\n",
        "  print('Sub-Optimal')\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Write Output\n",
        "input_data_df.to_csv(\"Demand and Output.csv\", index = False)\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ka70WfM8jGzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#---------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Data Creation\n",
        "monthly_planning_df = pd.read_csv(\"Monthly Planning Output.csv\")\n",
        "print()\n",
        "\n",
        "input_data_df = pd.DataFrame(columns=['Day', 'Date', 'Hour', 'Slot', 'Total Demand', 'Variation %', 'Final Demand', 'Demand Met', 'QoE %', 'Proposed Consumption Per Slot', 'Proposed Slot Speed', 'Actual Demand'])\n",
        "counter = 0\n",
        "for day in range(num_planning_days):\n",
        "  date = planning_start_date + timedelta(days=day)\n",
        "  for hour in range(hours_in_day):\n",
        "    row = monthly_planning_df[(monthly_planning_df['Day'] == day) & (monthly_planning_df['Hour'] == hour)]\n",
        "    total_demand = row['Total Demand'].iloc[0]\n",
        "    variation_percentage = row['Variation %'].iloc[0]\n",
        "    final_demand = row['Final Demand'].iloc[0]\n",
        "    demand_met = row['Demand Met'].iloc[0]\n",
        "    qoe_percentage = row['QoE %'].iloc[0]\n",
        "    proposed_consumption_per_slot = row['Proposed Consumption Per Slot'].iloc[0]\n",
        "    proposed_slot_speed = row['Proposed Slot Speed'].iloc[0]\n",
        "\n",
        "    for slot in range(slots_per_hour):\n",
        "      input_data_df.loc[len(input_data_df)] = [day, date, hour, slot, total_demand, variation_percentage, final_demand, demand_met, qoe_percentage, proposed_consumption_per_slot, proposed_slot_speed, \"\"]\n",
        "\n",
        "  if counter >= days_to_consider:\n",
        "    break\n",
        "  counter += 1\n",
        "\n",
        "\n",
        "#Write Output\n",
        "input_data_df.to_csv(\"Live Execution Output.csv\", index = False)"
      ],
      "metadata": {
        "id": "bl17TXkBD8Ho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}